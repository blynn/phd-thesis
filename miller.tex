\chapter {The Weil and Tate Pairings}

The Weil and Tate pairings take \emph{$r$-torsion points}
as input, and in the case of the Weil pairing, both inputs are
$r$-torsion points.
They can be defined using \emph{rational functions}.
They output an element of a finite field that is an $r$th root of unity.

\section {Torsion Points}

Let $K$ be a finite field of characteristic $q$, so that
$K = \mathbb{F}_{q^m}$ for some natural number $m$.
Let $E$ be an elliptic curve defined
over $K$. Let $n=\#E(K)$
Suppose $P\in E(K)$ satisfies $r P = O$, so that $P$ has order $r$ or a
factor of $r$.
We call $P$ an \emph{$r$-torsion point}.
We denote the set of $r$-torsion points in $E(K)$ by
$E(K)[r]$.

For the curves we shall consider,
$n$ and $q$ are always coprime thus $r$ is also coprime to $q$
(since $r \mid n$).
The case when $r$ is not coprime
to $q$ leads to \emph{the anomalous attack}~\cite[Section V.3]{bss}
which breaks discrete log in linear time.

It can be proved~\cite{silverman} that for some integer $k \ge 1$,
$E(\Fqk)[r]$ contains exactly $r^2$ points and is isomorphic to
$\mathbb{Z}_r^+ \times \mathbb{Z}_r^+$,
and furthermore, for all $k' \ge k$ we have $E(\mathbb{F}_{q^{k'}})[r]
= E(\Fqk)[r]$.
Roughly speaking, there are no other $r$-torsion points beyond the
first $r^2$ points found, no matter how many times we extend the field.
(That is, if $\bar{K}$ is the algebraic closure of $K$ then $\#E(\bar{K})[r] = r^2$.)
We define $E[r] = E(\Fqk)[r]$, the set of
\emph{$r$-torsion points} of $E$.

It can be shown that $E[r]$ is the product of two cyclic groups of order $r$:

\[ E[r] \cong \mathbb{Z}_r \times \mathbb{Z}_r . \]

When $r=2$ this is easy to see: a point has order 2 if and only if it has
a zero $y$-coordinate. Since $E$ is nonsingular,
$x^3 + ax + b = 0$ has three distinct solutions, thus we can always find
some field $\Fqk$ where $E$ has
four points of order 2: the point $O$ and three points of the form
$(\alpha, 0)$ where $\alpha$ is a root of the cubic.
Since the line through any two of the finite points is simply the line $Y = 0$,
which certainly intersects $E$ at the other finite point, we have
$E[2] \cong \mathbb{Z}_2 \times \mathbb{Z}_2$.
The proof is much less trivial for general $r$.

The Weil pairing is a bilinear map
takes pairs of elements from $E[r]$ and outputs an $r$th root of unity
in $\Fqk$. The Tate pairing is similar but only the first
input is from $E(\Fq)[r]$.

\section {Rational Functions}

We study the behaviour of quotients of polynomials in two variables on
points on an elliptic curve.

We denote the ring of polynomials in two variables $X,Y$
with coefficients in $\Fqk$ by $\Fqk[X,Y]$. 

Let $E$ be an elliptic curve $Y^2 = X^3 + aX + b$ over $\Fqk$.
Write $E(X,Y)$ for the polynomial $Y^2 - X^3 - aX - b$.
It can be shown that a polynomial $f$ satisfies $f(X,Y) = 0$
whenever $E(X,Y) = 0$ if and only if $f(X,Y)$ is a multiple of $E(X,Y)$.

Thus define $\Fqk[E] = \Fqk[X,Y]_{E(X,Y)}$. In other words we look at all
possible polynomials and consider two of them to be
equivalent if they take the same values on all points of $E$.
Every element $f(X,Y)$ in $\Fqk[E]$ can be written in the form
$f_x(X) + Y f_y(X)$ for polynomials $f_x, f_y \in \Fqk[X]$ because
we may replace $Y^2$ by $X^3 + aX + b$.

Define $\Fqk(E)$ to be the field of fractions of $\Fqk[E]$.
Elements of $\Fqk(E)$ can be written in the form
$f(X,Y) / g(X,Y)$ where $f, g$ are polynomials in two variables $X, Y$
and $g$ is not a multiple of $E$.

\section {Curve Endomorphisms}

Given a point $P$ and integer $m$ consider the \emph{multiplication by $m$ map}
$[m]$ given by \[ P \mapsto m P . \]
If $P$ is viewed as a pair of variables $(X,Y)$, this map
can be written as $(f(X,Y), g(X,Y))$ for some rational functions $f,g$.
(Using the explicit formulas for point addition and doubling
given in the previous chapter, we can write down
explicit formulas for $f$ and $g$ for any $m$, but even for relatively
small $m$ the expressions are unwieldy.)

This is an example of a \emph{curve endomorphism}, because points of
$E(\Fqk)$ are mapped to points of $E(\Fqk)$. Another important example
is the $q$th power \emph{Frobenius map} $\Phi$,
given by $(X, Y) \mapsto (X^{q}, Y^{q})$. (In general one defines
$q^k$th power Frobenius maps but we only define the $q$th power map,
and if we need higher powers $k$ we shall write $\Phi^k$.)

\begin{theorem}
[Hasse]
\[ \Phi^k \circ \Phi^k - [t] \circ \Phi^k + [q^k] = [0] \]
where $t = q^k + 1 - \#E(\Fqk)$.
\end{theorem}

Since $E[r] \cong \mathbb{Z}_r \times \mathbb{Z}_r$ any curve endomorphism
that maps $E[r]$ to $E[r]$ (which is true for Frobenius and
multiplication-by-$m$ maps)
can be viewed as a $2\times 2$ matrix when restricted to $E[r]$.

In particular for a prime $r$ dividing $\#E(\Fq)$ the eigenvalues
of $\Phi$ are the solutions to $x^2 - t x + q \pmod{r}$.
The polynomial factorizes as $(x - q)(x - 1)$ thus any eigenvalues
must be $q$ or $1$. We can describe the corresponding eigenspaces.

Clearly $E(\Fq)[r]$ is a $1$-eigenspace, hence if $E[r] \subset E(\Fq)$
then $\Phi$ is simply the identity.

Otherwise consider the set $G = \{P \mid \tr P = O \}$
where the trace is defined by
\[ \tr P = P + \Phi(P) + ... + \Phi^{k-1}(P)  .\]

We know this set contains more than just the point at infinity
since for any $P \in E[r] \setminus E(\Fq)[r]$,
the point $P - \Phi(P)$ is nontrivial and has trace zero.
Straightforward computations show that $G$ is closed under the group laws,
and also show that $\Phi(G) = G$. Hence $G$ is an eigenspace.

As $G$ cannot be the $1$-eigenspace (which has already been accounted for;
$E(\Fq)[r]$ is the $1$-eigenspace), $G$ must be the $q$-eigenspace,
which implies $|G| = r$.

This result will be important later, so we restate it:

\begin{theorem}
The set of points of trace zero
$G = \{P \mid \tr P = O \}$ is a cyclic group of order $r$,
and every $P \in G$ satisfies $\Phi(P) = q P$.
\end{theorem}

\section {Zeroes and Poles}

When we study a polynomial $f(X)$, the roots of $f(X)$ play an important
role. For example, if the roots are $\alpha_1,...,\alpha_n$ we may
instantly write down a polynomial with those roots, unique up to a constant:
$(X-\alpha_1)...(X-\alpha_n)$. Then when considering the quotient of
two polynomials $f(X)/g(X)$, we see the zeroes are the roots of $f$ and
the poles are the roots of $g$.

One way to view roots is to view them as places where the curve $Y = f(X)$
intersects with the curve $Y = 0$. We now generalize by replacing $Y=0$
with an elliptic curve.

When studying an element $f(X,Y) \in \Fqk[E]$, we take note of points of
intersection between $f(X,Y)$ and $E$.
We call these points of intersection \emph{zeroes} of $f$.

For example, consider the case $f(X,Y) = X-x$ for some $x\in\Fqk$.
Then $X-x$ intersects $E$ at one, two, or zero places depending
on whether $x^3 + a x + b$ is nonzero, and if so, whether it is a quadratic
residue or not.
We immediately see that zeroes in this case are harder to work with than
zeroes of a polynomial: given a polynomial $X - x$ we know it has
exactly one root $x$, while for elliptic curves, it may have 0,1, or 2
zeroes.

There are further complications. When $X - x$ intersects $E$ at one point,
it is analogous to a repeated root of a polynomial: it is in
fact a zero of multiplicity 2. The point at infinity also needs to be
considered. It turns out that, roughly speaking, any equation of a line
has a pole of mulitplicity 3 at $O$, but since $X - x$ passes through $O$,
$X-x$ has a pole of multiplicity 2 at $O$.

Recall an element of $\Fqk(E)$ can be written as $f(X,Y)/g(X,Y)$.
In this case the zeroes are the zeroes of $f$ and the poles of $g$,
and the poles are the poles of $f$ and the zeroes of $g$.

Note that knowing the zeroes and poles of the quotient of two
polynomial $f(X)/g(X)$ allows us to write down $f(X)/g(X)$ (up to multiplcation
by a constant factor). Suppose the zeroes and poles are $\alpha_1,...,\alpha_n$
with mulitplicites $a_1,...,a_n$ where $\alpha_i$ is a zero of multiplcity
$a_i$ if $a_i > 0$, and otherwise a pole of multiplicity $-a_i$. Then
we may write $f(X)/g(X)$ immediately by multiplying equations of
vertical lines correctly:

\[ f(X)/g(X) = (X-\alpha_i)^{a_i} \]

It turns out knowing the zeroes and poles of
a rational function on $E$ also allows us to instantly write its equation,
up to multiplication by a constant. We also build up the function by
multiplying together equations of lines, but not just using
vertical lines.

In what follows,
by abuse of notation we often refer to a single rational function
$f$ when in fact we are considering a whole family of rational functions
$c f$ for some nonzero constant $c$. To add to the confusion, having
chosen a representative of a family, we will sometimes subsequently
insist on using that same representative. The reasons for doing so
will become clear.

\section {Divisors}

Divisors are the standard way
to notate zeroes and poles and their multiplicities.
If we wish to record zeroes and poles $P_1,...,P_n$
of orders $a_1,...,a_n$ (where $P_i$ is a zero of order
$a_i$ if $a_i > 0$ and is a pole of order $-a_i$ otherwise), then
we may write:
\[ D = a_1\langle P_1\rangle + ... + a_n \langle P_n\rangle .\]

With this notation, if we add the divisors of two functions together,
then the resulting divisor reflects the zeroes and poles of the product
of the two functions.

For this chapter we break with tradition and use multiplicative
notation for divisors instead. In addition, we will omit an arbitrary
number of poles or zeroes at $O$. This is not problematic because we
will always be discussing principal divisors, thus the true multiplicity
of $O$ can be computed from the multiplicities at the finite points.

Let $D$ be the divisor with zeroes and poles $P_1,...,P_n$
of mulitplicities $a_1,...,a_n$.
We shall write $D$ as
\[ D = (P_1)^{a_1} ... (P_n)^{a_n} . \]
Furthermore if $D$ is a principal divisor, we will
omit as many $(O)$ terms as we like, as its real order
can be calculated simply by negating
of the sum of the orders of the other zeroes and poles.
(If we need to switch to conventional notation we will use angled brackets
rather than parentheses.)

On an elliptic curve, in our unorthodox notation:
\begin{description}
\item[Lines:]
a line $L$ through the points $P, Q$ has divisor
\[ (L) = (P)(Q)(-P-Q) . \]
\item[Tangents:]
when $Q = P$ we have a tangent line $T$ at $P$ with divisor
\[ (T) = (P)^2 (-2P) . \]
\item[Verticals:]
when $Q = -P$, we have a vertical line $V$ through the point $P$
with divisor
\[ (V) = (P)(-P) . \]
\end{description}

There are advantages to using this notation. Using additive group
notation for the elliptic curve and mutlplicative notation for the divisor
group emphasizes the difference between them and reduces the likelihood of
confusing the two. When rational functions are multiplied together,
their divisors can be multiplied together, which is arguably
more natural than adding them.
Leaving out as many $(O)$ terms as we choose allows us to focus less on
bookkeeping and more on the task at hand.
The correct multiplicity of $(O)$ can always be determined later.

We use
$(f)$ to denote the divisor of $f$, thus in our notation
for any rational functions $f, g$ we have $(f)(g) = (f g)$.

\section {The Weil Pairing}

Earlier papers on pairing-based cryptosystems advocated the Weil pairing.
We shall see that the related Tate pairing is preferable for our purposes.
Nonetheless we first describe the Weil pairing
for historical reasons, and also because its simpler description
serves well as an introduction. The inputs to the Tate pairing come
from different groups, and the definition involves quotient groups,
which can obscure the basic idea. However, the actual computation
of the Tate pairing is simpler.

Let $E$ be an elliptic curve containing $n$ points over a field $\mathbb{F}_q$.
Let $G$ be a cyclic subgroup of $E(\mathbb{F}_q)$ of order $r$ with $r, q$
coprime. Let $k$ be the smallest positive integer such that $E(\Fqk)$
contains all of $E[r]$.

We define the Weil pairing
$f:E[r] \times E[r] \rightarrow \Fqk$ as follows.

For a pair of points $P, Q \in E[r]$,
choose any $R, S \in E[\Fqk]$ such that $S \ne R, P+R, P+R - Q, R-Q$.
Let $f_P$ be a rational function with divisor $(f_P) = (P+R)^r /(R)^r$,
(In other words, we have $r$ zeroes at $P+R$ and $r$ poles at $R$.
In standard notation this is $r\langle P+R\rangle  - r\langle R\rangle$.)
and similarly let $f_Q$ be a rational function with divisor
$(f_Q) = (Q+S)^r/(S)^r$.

Define
\[ f(P,Q) = \frac{f_P(Q+S)/f_P(S)}{f_Q(P+R)/f_Q(R)} \]

Using Weil reciprocity it can be shown that this value is independent
of the choices for $R, S$. The conditions for choosing $R, S$ ensure
we never evaluate $f_P$ nor $f_Q$ at a zero or pole.
Also both $f_P, f_Q$ are only unique up to a constant,
but this has no effect on the final answer since quotients
of these functions are computed and the constants cancel out.

This is an example of the grey area mentioned earlier:
at first we are free to choose
any function as long as they have certain zeroes and poles, but we cannot
alter it once we have made a choice.

Finding explicit expressions for these functions is infeasible for
cryptographically useful pairings. Instead, we will soon describe
an algorithm, known as \emph{Miller's algorithm}~\cite{miller}
that evaluates these functions in a lazy fashion at the required
points. This algorithm resembles a typical exponentiation routine
that performs repeating squaring.

One can prove~\cite{silverman} that
\begin{enumerate}
\item
$f(a P, b Q) = f(P,Q)^{a b}$ for all $P, Q \in E[r]$ and all integers $a, b$.
\item
$f(P,P) = 1$ for all $P \in E[r]$.
\item
$f(P,Q) = 1$ for all $P \in E[r]$ if and only if $Q = O$.
\item
$f(P,Q) = 1$ for all $Q \in E[r]$ if and only if $P = O$.
\item
$f(P,Q) = f(Q,P)^{-1}$ for all $P,Q \in E[r]$.
\item
$f(\Phi(P),\Phi(Q)) = f(P,Q)^{q}$ for all $P,Q \in E[r]$.
where $\Phi$ denotes the Frobenius map.
\end{enumerate}

(The last property is usually stated more generally:
$f(\alpha(P),\alpha(Q)) = f(P,Q)^{\deg \alpha}$ for any nonzero
endomorphism $\alpha$.)

The second to last property, known as antisymmetry, is a property the
Tate pairing does not have. However it does not yet have
any use in cryptography.

Let $P$ be a generator of $G$. Suppose
we have a linear map
\[ \phi : E[r] \rightarrow E[r] \]
where $Q = \phi(P)$ linearly independent to $P$ and also generates
a group of order $r$.
Then defining $e:E[r]\times E[r]\rightarrow \Fqk$ by
\[ e(g,h) = f(g,\phi(h)) \]
for all $g, h \in G$
gives a symmetric bilinear nondegenerate map.

For efficiency, if possible we have $k > 1$, and choose
$G = E(\Fq)[r]$, namely the
group of points $P \in E(\Fq)$ satisfying $r P = O$.

\section {The Tate Pairing }

Let $E$ be an elliptic curve containing $n$ points over a field $\mathbb{F}_q$.
Let $G$ be a cyclic subgroup of $E(\mathbb{F}_q)$ of order $r$ with $r, q$
coprime. Let $k$ be the smallest positive integer such that $r \mid q^k - 1$.
For brevity write $K = \Fqk$.

An equivalent characterization is that
$\Fqk$ is the smallest extension of $\Fq$ containing the $r$th roots of unity.

The Tate (or Tate-Lichtenbaum) pairing
\[
e : E[r] \cap E(K) \times
E(K) / r E(K) \rightarrow
K^* / K^{*r}
\]
is defined as follows.

Let $f_P$ be a rational function with divisor $(f_P) = (P)^r$.
Choose an $R\in E(K)$ such that $R \ne P, P-Q, O, -Q$. The define
\[
f(P, Q) = f_P (Q + R) / f_P (R)
\]

It can be shown that the above value is independent of the choice of $R$,
and:
\begin{enumerate}
\item
$f(a P, b Q) = e(P, Q)^{a b}$ for all $P, Q, a, b$.
\item
$f(P,Q) = 1$ for all $P$ if and only if $Q = O$.
\item
$f(P,Q) = 1$ for all $Q$ if and only if $P = O$.
\item
$f(\Phi(P),\Phi(Q)) = f(P,Q)^{q}$ for all $P,Q \in E[r]$,
where $\Phi$ denotes the Frobenius map.
\end{enumerate}

The output of this pairing is some $x \in K^*$
that represents the coset $x K^{*r}$. To standardize the coset
representative, we exponentiate the output of the Tate pairing
by $(q^k - 1) / r$, which can take a substantial amount of time.

On the positive side, the second input to the Tate pairing is also a coset
representative. This means it can be any point of $E(K)$ and may
be of any order. (For example,
if the order of a point $Q$ is not a mulitple of $r$ then $Q$ represents
the coset $O + r E(K)$. Otherwise $Q$ represents some nonidentity
element.)

In contrast, the Weil pairing requires that the second
input $Q$ satisfies $r Q = O$.

\section {Merging Theory with Practice}

We have now described the Weil and Tate pairings. It remains to show
how they fit the abstract definitions given in Chapter 1.

Let $E$ be some elliptic curve defined over $\Fq$ and let $G$ be some
cyclic subgroup of points in $E(\Fq)$ of order $r$.
Suppose the embedding degree of $G$ is $k > 1$.

Then by defining $G_1 = G$, $G_2 = E[r]$, and $G_T$ to be the $r$th roots
of unity in $\Fqk$, the Weil pairing satisfies the abstract
definition of a bilinear map given in Section~\ref{sec:generalpairing}.
Fitting the Tate pairing to the definition is similar.

With high probability, a random point $Q \in G_2$, does not
lie in $G_1$, does not have trace zero,
and generates a subgroup $H$ in $G_2$ of order $r$. Then
if we replace $G_2$ with $H$, we have now satisfied the asymmetric pairing
definition of Section~\ref{sec:asymmetricpairing} because the
trace map nontrivially maps $G_2$ to $G_1$.

Symmetric pairings described in Section~\ref{sec:symmetricpairing} can only
be obtained by using supersingular curves and distortion maps, which
we discuss in Section~\ref{sec:inputrestriction}.

We see now why we cannot hash into $G_2$ in general if it is required
to be cyclic.
In the case of the Weil pairing, we can easily hash to a point of $E[r]$,
but it is not known how to hash to an point of
some cyclic subgroup of $E[r]$ of order $r$ that is not $G$. 
For the Tate pairing we have a similar problem.

\section {Miller's Algorithm}

For the Weil pairing we need to evaluate some rational function
$f_P$ with divisor $(P+R)^r /(R)^r$.
For the Tate pairing we need to evaluate some rational funciton
$f_P$ with divisor $(P)^r$.
In both cases, we can do this using Miller's algorithm~\cite{miller}.

For any points $U, V$,
let $L_{U,V}(X,Y)$ be an equation for a line through $U$ and $V$,
let $T_{U}(X,Y)$ be an equation for the tangent through $U$.
let
$V_{U}(X,Y)$ be an equation for a vertical line through $U$ (e.g.
$X - x$, where $U = (x, y)$).

Actually, $T_U$ and $V_U$ are unnecessary since
$T_U = L_{U,U}$ and $V_U = L_{U,-U}$, but they are convenient notation.
Also if $U = -U$ then $T_U$ is the same as $V_U$.

\subsection {The Weil Pairing}

Let us handle the Weil pairing first. For an integer $k$, let
$f_k$ be a rational function with divisor
\[
(f_k) = \frac{(P+R)^k}{(R)^k(kP)} .
\]

Observe $f_r = f_P$, since $rR = O$.
It can be checked that
\[
\left(
f_a \cdot f_b \cdot \frac{L_{aP,bP}}{V_{(a+b)P}}
\right) = (f_{a+b})
\]
via a simple computation on the divisors:
\[
\frac{(P+R)^a}{(R)^a(aP)}
\cdot
\frac{(P+R)^b}{(R)^b(bP)}
\cdot
\frac{(aP)(bP)(-(a+b)P)}{(a+b)P(-(a+b)P)}
=
\frac{(P+R)^{a+b}}{(R)^{a+b}((a+b)P)} .
\]
This leads to the formula:
\[
\left(
f_k^2 \cdot \frac{T_{kP}}{V_{2kP}}
\right) = (f_{2k})
\]

A straightforward manipulation of divisors also shows
$( V_{P+R} / L_{P,R}) = (f_1)$.

Thus we may compute $f_P(Q) = f_r(Q)$ using the following algorithm,
where the binary representation of $r$ be $r_t ... r_0$.

\begin{algorithm}
\caption{Miller's algorithm for Weil pairing. $x = f_P(Q)$}
\begin{algorithmic}[1]
\STATE $x_1 \gets V_{P+R}(Q) / L_{P,R}(Q)$
\STATE $x \gets x_1$
\STATE $Z \gets P$
\FOR {$i \gets t-1, ..., 0$}
    \STATE $x \gets x^2 \cdot T_Z(Q) / V_{2Z}(Q)$
    \STATE $Z \gets 2Z$
    \IF {$r_i = 1$}
	\STATE $x \gets x \cdot x_1 \cdot L_{Z, P}(Q) / V_{Z+P}(Q)$
	\STATE $Z \gets Z + P$
    \ENDIF
\ENDFOR
\end{algorithmic}
\end{algorithm}

On termination, we have $x = f_P(Q)$ (and $Z = rP = O$).

Throughout the algorithm we may multipy the equation of any line $L, T, V$
by an arbitrary constant, thus more precisely, this algorithm
really computes $f_P(Q)$ for one possible choice of $f_P$.
In the Weil pairing,
this causes no problems provided the same equations are chosen the second
time this algorithm is run, so that the exact same $f_P$ is evaluated.

Note that
\[
\left(
f_k \cdot \frac{L_{P+R,kP}}{L_{R,(k+1)P}}
\right) = (f_{k+1}) .
\]
thus could replace step 3(c)(i) with
$x \gets x \cdot L_{P+R, Z}(Q) / L_{R,Z+P}(Q)$
and avoid computing and storing $x_1$, but unless
$r$ has very low Hamming weight this is not a good trade
because computing vertical lines is much cheaper than general lines.

\subsection {The Tate Pairing}

We now consider the Tate pairing. Recall we wish to compute
$f_P(Q)$ where $f_P$ has divisor $(P)^r$.

We can view our current situation as a special case of the above
with $R = O$.
Thus define the intermediate functions $f_k$ by
\[ (f_k) = (P)^k / (kP) . \]
We have $(f_r) = (f_P)$.
The following identities can be obtained by simplifying
earlier formulas using $R=O$, but it is easy enough to check them directly.

For example, we can show
\[ (f_k) = \left(\prod_{i=1}^{k-1} \frac{L_{iP}}{V_{(i+1)P}}\right) \]
via
\[ (f_k) =
\frac{(P)(P)}{(2P)}
\cdot
\frac{(P)(2P)}{(3P)}
\cdots
\frac{(P)((k-1)P)}{(kP)} .
\]
We could compute $f_r(Q)$ using this formula,
but this is clearly impractical for large $r$.

We find
\[
(f_{2k}) = (f_k^2 T_{kP} / V_{2kP} )
\]
which can be shown with direct calculation:
\[
\frac{(P)^{2k}}{(2kP)} =
\frac{(P)^{2k}}{(kP)^2} \cdot
\frac{(kP)^2 (-2kP)}{(2kP)(-2kP)}
\]
and similarly we can show
\[
(f_{k+1}) = (f_k L_{kP} / V_{(k+1)P}).
\]
leading to the following algorithm that
computes $f_P(Q)$ given points $P,Q$ (where $P$ has order $r$).
Let the binary representation of $r$ be $r_t ... r_0$.

\begin{algorithm}
\caption{Miller's algorithm for Tate pairing. $x = f_P(Q)$}
\begin{algorithmic}[1]
\STATE $x \gets 1$
\STATE $Z \gets P$
\FOR {$i \gets t-1, ..., 0$}
    \STATE $x \gets x^2 \cdot T_Z(Q) / V_{2Z}(Q)$
    \STATE $Z \gets 2Z$
    \IF {$r_i = 1$}
	\STATE $x \gets x \cdot L_{Z,P}(Q) / V_{Z+P}(Q)$
	\STATE $Z \gets Z + P$
    \ENDIF
\ENDFOR
\end{algorithmic}
\end{algorithm}

When the algorithm finishes we have $x = f_r(Q)$ (and $Z = rP = O$).
Note this algorithm can be viewed as the previous algorithm with $x_1 = 1$.

\subsection {Intermediate Poles and Zeroes}

There are complications however. The intermediate functions have zeroes
and poles that eventually cancel out. If we were dealing with algebraic
expressions for the rational function then we could manipulate
them to remove these zeroes and poles at some stage.
But since we are evaluating the function as we go,
this cannot be done, and attempting to evaluate an
intermediate function at a zero
or pole will cause problems.

Recall we have an almost unrestricted choice for the points $R, S$ in
the Weil pairing and also for the point $R$
in the Tate pairing. To use Miller's algorithm, we choose them
to avoid the zeroes or poles
of the intermediate functions. One way to do this is to choose
these points at random (since there are only $O(t)$ bad choices).

Alternatively we may ensure their coordinates do not lie in the
field that the functions are defined in, but rather in some field
extension, so that in the case of a Weil pairing, $P+R$, $R$, $Q+S$, $S$
cannot possibly be a zero or pole in the intermediate functions
(though we must still avoid choices such as $R = S$),
and in the case of a Tate pairing, neither $R$ nor $Q + R$
can be a zero or pole.

We shall see that under some conditions there is a much simpler solution
for the Tate pairing.

\section {Worked Examples}

Consider the curve $E : Y^2 = X^3 + X$ over $\F_{59}$.
This has 60 points. Let $G$ be the subgroup of size $r = 5$.
One generator of $G$ is $P = (25, 30)$:
\[ G =
E(\F_{59})[5] =
\{P = (25, 30), 2P = (35, 31), 3P = (35, 28), 4P = (25, 29), 5P = O \} \]

Feeding any two of these points as inputs to the Weil pairing is pointless
as the output will be 1 since they are linearly dependent. We must first
find other 5-torsion points.

The Tate pairing is also useless at the moment, because $5 \nmid 59 - 1$,

But $5 \mid 59^2 - 1$, and we will see that $E(\F_{59^2})$ contains
all 25 points of $E[5]$, so in the field extension $\F_{59^2}$
both the Tate pairing
and Weil pairing exist and are nontrivial.
Note $-1$ is a quadratic nonresidue in $\F_{59}$
so we may write $\F_{59^2} = \F_{59}[i]$ where $i = \sqrt{-1}$.

It also turns out that the so-called distortion map given by
$\phi(x,y) = (-x, i y)$ enables us to write down all of $E[5]$ easily.
This map $\phi$ takes $G$ to another subgroup $G'$ in $E[5]$:
\[ G' =
\{Q = (-25, 30i), ..., 4Q = (-25, 29i), 5Q = O \} \]
where $Q = \phi(P)$,
and every element of $E[5]$ can be written as a sum of an element in $G$
and an element in $G'$.

\subsection {The Weil Pairing}

Let us first consider the Weil pairing, which we denote by $f$.
We walk through the computation of $f((25,30), (-25,30i))$.
The two inputs points are linearly independent thus the output is not 1.

Computing $f(P, Q)$ entails evaluating several rational functions
at various points that depend on two picked points $R$ and $S$.
These points $R$ and $S$ must be selected so that we never encounter a
zero or pole while evaluating these functions.

In practice, the probability that randomly chosen $R, S$ are unsuitable
is negligible. This is not the case for our toy example, but it turns
out that choosing $R = (40,54)$ and $S = (48+55i,28+51i)$
will work. Note that $R, S$ do not need to lie in $E[5]$.

We describe in detail how Miller's algorithm arrives at $f_P(Q+S) = f_5(Q+S)$:
\begin{enumerate}
\item
We compute $f_1 = V_{P+R} / L_{P,R}$.
Using the point addition formulas we find $P+R = (6,24)$
and $Q+S=(19+17i, 46+18i)$.
Then
from the explicit formulas given earlier we have
\[ V_{P+R} : X + 53 \]
\[ L_{P,R} : 35 X + 15 Y + 32 \]
Evaluating both equations at $Q + S$ and taking their quotient
gives $x_1 = f_1(Q+S) = 25 + 31i$.
\item
We now enter the main loop.
Firstly, $f_2 = f_1^2 T_{P} / V_{2P}$ where
\[ T_{P} : 12 X + Y + 24 \]
\[ V_{2P} : X + 24 \].
Then we assign $x \gets x_1^2 T_{P}(Q+S) / V_{2P}(Q+S)$
which turns out to be $(18 + 16i)(3+45i)/(43+17i) = 33 + 22i$.
\item
Since the second bit of $5 = 101_2$ is zero, the condition for the if statement
is false and the next iteration begins. Now
$f_4 = f_2^2 T_2 / V_4$, where
\[ T_{2P} : 53 X + Y + 2 \]
\[ V_{4P} : X + 34 \].
and we compute $x \gets x^2 T_{2P}(Q+S) / V_{4P}(Q+S)$.
It can be checked $x = 58 + 23i$ now.
\item
The last bit is 1, so this time we do execute the contents of the if block,
namely $x=\gets x \cdot x_1 \cdot L_{4P,P}(Q+S)/V_{5P}(Q+S)$.
Since $5P = O$ we discard the denominator in this case, and since $P = -4P$,
$L_{4P, P} = V_P$ which is given by
\[ V_P : X + 34 \] thus $x = (58+23i)(25+31i)(53+17i) = 18 + 2i$,
and the algorithm stops as we have exhausted all the bits.
\end{enumerate}

Thus we have found that $f_P(Q+S) = 18+2i$, and yet we have not found
an algebraic expression for the rational function $f_P$.

We can repeat the above to find $f_P(S) = 10 + 30i$, but clearly a better way
is to compute $f_P(S)$ concurrently to avoid repeating the same operations.
In other words, we simultaneously calculate $f_P(Q+S)$ and $f_P(S)$, and
as each equation for a certain line is found,
we evaluate at $Q+S$ and also at $S$.

The computation of $f_Q(P+R)$ and $f_Q(R)$ is similar (note since
$Q$ does not lie in $\Fq$ the $L,T,V$ equations will involve imaginary
numbers), and it can be verified that
$f_Q(P+R) = 27+25i$ and $f_Q(R)=10+41i$.

At last we have
\[
f(P,Q) = \frac{f_P(Q+S)/f_P(S)}{f_Q(P+R)/f_Q(R)} = 46+56i .
\] Thankfully $(46+56i)^5 = 1$ as expected.

\subsection {The Tate Pairing}

Let $f$ denote the Tate pairing.
Again we walk through the computation of
$f((25,30), (-25,30i))$.

In a later chapter we shall show that in this case,
for all $R$ we have $f_P(Q) = f_P(Q+R)/f_P(R)$.
thus we only walk through the calculation of
$f_P(Q)$.
Nonetheless, calculating $f_P(Q+R)$ and $f_P(R)$ can be done in
a similar fashion.

\begin{enumerate}
\item
$f_2(Q) = f_1(Q)^2 T_P (Q) / V_{2P}(Q)$.
Note $f_1 = 1$, unlike the Weil pairing.
From the formulas given before we can find equations describing
the tangent $T_P = 0$ at $P$ and the vertical line $V_{2P} = 0$ at $2P$:
\[ T_1 : 12 X + Y + 24 \]
\[ V_2 : X - 35 \]
(We may write $X + 34$ instead, it doesn't matter.)

As stated before there are other choices for the equations.
If we were computing $f_P(Q+R)$ and $f_P(R)$ we would need
to use the same choices both times. However, for our current case it
can be shown
there are no restrictions save that the coefficients of the functions
lie in $\Fq$.

From
$T_1(34, 30i) = 12 \times 34 + 30i + 24 = 19 + 30i$ and
$V_2(34, 30i) = 34 - 35 = 58$
we obtain $f_2(Q) = (19 + 30i) / 58 =  40 + 29i$.
\item
$f_4(Q) = f_2(Q) ^2 T_2 (Q) / V_4(Q)$ where
\[ T_2 : 53 X + Y + 2 \]
\[ V_4 : X - 25 \]
We have
$T_2(34,30i) = 53 \times 34 + 30i + 2 = 34 + 30i$ and
$V_4(34,30i) = 34 - 25 = 9$ Thus
$f_4 = (40 + 29i)^2 \times (34+30i) / 9 = 31 + 32i$.
\item
$f_5 = f_4 L_4(Q) / V_5(Q)$
We discard $V_5$ since $5P = O$, and $L_4$, the line between $P$ and $4P = -P$
is in fact a vertical line:
\[ L_4: X - 25 \]
Since
$L_4(34, 30i) = 34 - 25 = 9$, we have
$f_5 = 9(31 + 32i) = 43 + 52i$.

In a larger example we would
come across lines $L$ that are not vertical (nor tangents).
\item
$f_P(Q)$ can be considered the output of the Tate pairing,
but it is a coset representative, and we standardize the representative
by raising it to the power of $(q^k - 1)/r$:
\[ f_P(Q)^{(q^k-1)/r} = (43+52i)^{(59^2 - 1)/5} = 42+40i \]
\end{enumerate}

As expected, $(42 + 40i)^5 = 1$.

\subsection {Remarks}
We point out a few peculiarities in the above examples, that will
have significance later.

In both examples,
degenerate cases appear in the last iteration
of the main loop.

Also, the vertical line $V_P$ appears
in the second-last iteration as well as last iteration, effectively canceling
itself out. After some thought it can be seen this will always happen
for odd $r$.

Whenever a vertical line is evaluated in the Tate pairing
example, the result is an element of $\Fq$.

The Weil pairing requires Miller's algorithm to be run twice, once for
$f_P(Q+S) / f_P(S)$ and once for $f_Q(P+R)/f_Q(R)$. In the computation
of $f_P$ every line equation has coefficients lying in $\Fq$, where
as to compute the equations of the lines, tangents and verticals of $f_Q$
we had to perform arithmetic in the larger field $\Fq[i]$.

The Tate pairing needs but one call to Miller's algorithm,
but requires an exponentiation by $(q^k - 1)/r$. Like the computation
of $f_P$ in the Weil pairing, to determine the equations of the lines,
tangents and verticals during Miller's algorithm only requires arithmetic
in the base field $\Fq$.

\section {Restricting Inputs}

We shall have much to say on this topic in Section~\ref{sec:inputrestriction},
but the above example serves as a good introduction.
Recall we have the Weil pairing $f$ on
the curve $E : Y^2 = X^3 + X$ over some field $\Fq$
where $q = 3 \bmod 4$. We have a distortion
map $\phi(x,y) = (-x, i y)$, and we have
a group $G$ of $r$-torsion points in $E(\Fq)$ for some $r$.

In real applications, we wrap the Weil pairing $f$ in another map
$e : G\times G \rightarrow \F_{q^2}$:
\[ e(U, V) = f(U, \phi(V)) . \]
We use $e$, not $f$, as our pairing.
There are at least two reasons for doing this.

The input points to $e$ have coordinates in $\Fq$ and lie on the
same curve (that is, $e$ is symmetrical) and

Both input groups of $e$ are cyclic.
Thus the construction of cryptosystems and their
security proofs are simpler. We could work with the
Weil pairing directly but then both input groups would be $E[r]$,
which is not cyclic.

As $U, \phi(V)$ are always linearly independent,
the wrapper function $e$ guarantees
a nontrivial pairing output whenever $U$ and $V$ are nontrivial.
This is not the case with the Weil pairing,
where one must be mindful of linearly dependent inputs.

Lastly, the input points have coordinates in the field $\Fq$ which is
smaller and hence more efficient to compute on than $\F_{q^2}$.

Similarly, if $f$ now denotes the Tate pairing,
we wrap $f$ in the map
$e : G\times G \rightarrow \F_{q^2}$:
\[ e(U, V) = f(U, \phi(V) + rG) \]
and use $e$ instead of $f$ in our cryptosystems.

\section {The Shipsey-Stange Algorithm}
There is another procedure for computing Tate pairings that takes a completely
different approach. We quote the algorithm as described by Stange~\cite{stange}
but omit explanations of the mathematical underpinnings.

Let $E:Y^2 = X^3 + aX + b$ be an elliptic curve over a field $K$.
Let $P=(x, y) \in E(K)[r]$, $Q=(x_2, y_2) \in E(K)$. ($Q$ represents the
coset $Q + rE(K)$.)
Define constants
\[
    A = (x - x_2)^{-1},
    B = \left((2x + x_2)(x - x_2)^2 - (y + y_2)^2\right)^{-1},
    C = (2 y)^{-1}
\]
Define the sequence $c_k$ by
\[
    c_{-2} = -2y,
    c_{-1} = -1,
    c_0 = 0,
    c_1 = 1,
    c_2 = 2 y,
\]
\[
\begin{array}{lcl}
    c_3 &=& 3 x^4 + 6ax^2 + 12bx - a^2, \\
    c_4 &=& 4y(x^6+5ax^4+20bx^3-5a^2x^2-4abx-8b^2-a^3), \\
    c_{2k-1} &=& c_{k+1} c_{k-1}^3 - c_{k-2} c_k^3, \\
    c_{2k} &=& C(c_k c_{k+2} c_{k-1}^2 - c_k c_{k-2} c_{k+1}^2).
\end{array}
\]
and the sequence $d_k$ by
\[
    d_0 = 1,
    d_1 = 1,
    d_2 = (2x+x_2) - \left( \frac{y_2-y}{x_2-x} \right) ^2
\]
\[
\begin{array}{lcrlcll}
    d_{2k-1} &=& & d_{k+1} d_{k-1} c_{k-1}^2 &-& d_k^2 c_{k-2} c_{k}& \\ 
    d_{2k} &=& & d_{k+1} d_{k-1} c_{k}^2 &-& d_k^2 c_{k-1} c_{k+1}& \\
    d_{2k+1} &=& A(& d_{k+1} d_{k-1} c_{k+1}^2 &-& d_k^2 c_{k} c_{k+2}&) \\
    d_{2k+2} &=& B(& d_{k+1} d_{k-1} c_{k+2}^2 &-& d_k^2 c_{k+1} c_{k+3}&) \\
\end{array}
\]
Then the Tate pairing
$
e : E[r] \cap E(K) \times
E(K) / r E(K) \rightarrow
K^* / K^{*r}
$
is given by
\[
e(P,Q) = d_{r+1}/c_{r+1}.
\]
We describe a repeated-squaring-like algorithm that uses these sequences
to compute the Tate pairing.
Let $r_t ... r_0$ be the binary representation of $r$.

\begin{algorithm}
\caption{(Shipsey-Stange) Tate pairing via elliptic nets. Outputs
$e(P,Q)$.}
\begin{algorithmic}[1]
\STATE $k \gets 1$
\STATE
Compute $A, B, C$ and $c_{k-3},...,c_{k+4}$ and $d_{k-1}, d_k, d_{k+1}$
($c_{-2}, ..., c_{5}$ and $ d_0, d_1, d_2$).
\FOR {$j = t-1$ to $0$}
    \IF {$r_j = 0$}
    \STATE (Double)
%use $c_{k-3}, ..., c_{k+4}$ to compute $c_{2k-3},...,c_{2k+4}$,
%and $d_{k-1}, d_k, d_{k+1}$ to compute $d_{2k-1}, d_{2k}, d_{2k+1}$.
Compute $c_{2k-3},...,c_{2k+4}$, and $d_{2k-1}, d_{2k}, d_{2k+1}$
(using the above recurrence relations)
    \STATE $k \gets 2k$
    \ELSE[$r_j = 1$]
    \STATE (Double and add)
%use $c_{k-3}, ..., c_{k+4}$ to compute $c_{2k-2},...,c_{2k+5}$.
%and $d_{k-1}, d_k, d_{k+1}$ to compute $d_{2k}, d_{2k+1}, d_{2k+2}$.
Compute $c_{2k-2},...,c_{2k+5}$ and  $d_{2k}, d_{2k+1}, d_{2k+2}$
(using the above recurrence relations)
\STATE $k \gets 2k + 1$
    \ENDIF
\ENDFOR
\RETURN $d_{r+1}/c_{r+1}$
\end{algorithmic}
\end{algorithm}

\subsection {Example}
We take the same curve and points from the other worked examples, that is
$E : Y^2 = X^3 + X$ over $\F_{59}$, $r = 5$,
$P = (25, 30)$, $Q = (-25, 30i)$.

\begin{enumerate}
\item
We find the constants are $A = 13, B = 25+55i, C = 1$,
start of the sequence $c_{-2}, ..., c_5 = 
56, 58, 0, 1, 3, 31, 37, 0$ and also $d_0, d_1, d_2 = 1, 1, 43+31i$.
We have $k = 1$. Note $c_5$ was computed using
$c_5 = c_2^3 c_4 - c_3^3$.
\item
We enter the main loop. As the second bit of the binary representation is
zero, we use the recurrence relations to find
$c_{-1}, ..., c_6$. As this is one of the first few iterations,
there is much overlap (which could be optimized away
in a real application), and the only new value is $c_6 = 53$. Similarly
we compute $d_1,d_2,d_3$ and the only new value is $d_3 = 2+43i$.
We have $k = 2$.
\item
The last bit is one, hence this time we find
$c_2, ..., c_9$. Once again there is overlap and the only new values
are $c_7 = 32, c_8 = 37, c_9 = 11$.
We also compute $d_4, d_5, d_6$ which turns out to be $55+13i, 51+26i, 26+4i$.
We exit the loop with $k = 5 = r$.
\item
The algorithm returns $d_6/c_6 = 37+42i$.
\end{enumerate}

In practice we power the result by
$(p^2 - 1)/r = 696$ (to standardize the coset representative),
giving the final answer of $42 + 40i$.

\subsection {Remarks}

The above example is artificially small, and we do not in fact need to bother
computing $c_7, c_8, c_9$. Also, many sequence values
are calculated more than once. For realistic sizes, this only happens in the
first few iterations, and the time taken by unnecssary computations
is a small fraction of the total running time. Nonetheless, checks to avoid
superfluous operations can be easily implemented for a slight efficiency gain.

There are many common subexpressions in the above formulas which
would be exploited in an implementation but were omitted above
for clarity. Setting
\[
S_k = c_k^2, T_k = c_{k-1} c_{k+1}, U_k = d_k^2, V_k = d_{k-1}d_{k+1}
\]
yields
\[
\begin{array}{lcl}
    c_{2k-1} &=& T_k S_{k-1} - T_{k-1} S_k, \\
    c_{2k} &=& C(T_{k+1} S_{k-1} - T_{k-1} S_{k+1}) \\
    d_{2k-1} &=& V_k S_{k-1} - U_k T_{k-1} \\ 
    d_{2k} &=& V_k S_{k} - U_k T_k \\
    d_{2k+1} &=& A(V_k S_{k+1} - U_k T_{k+1}) \\
    d_{2k+2} &=& B(V_k S_{k+2} - U_k T_{k+2}) \\
\end{array}
\]
though we note sometimes it is better to compute $c_{2k}$ via
\[
    c_{2k} = C c_k (c_{k+2} c_{k-1}^2 - c_{k-2} c_{k+1}^2).
\]
as in some cases, certain $T_k$ subexpressions are only used once.
